%
% File acl2017.tex

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2017}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

%uncomment line below for author names to appear. 
%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

\setlength\titlebox{5cm}

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Stance Detection \& Fake News \\ NLG Proposal}

\author{
  Bernice Brown \\
					  \\
					  \\\And
  Brian Chen 	      \\
					  \\
					  \\\And
  Tahya Weiss-Gibbons \\
					  \\
					  \\\And
  Nicholas Kobald \\  \\
}
\date{}
\begin{document}
\maketitle
\section{Introduction}
The term \emph{Fake News} has gained popularity following the 2016 United States presidential election and the vote for the United Kingdom to exit the European Union \cite{rose2017brexit}\cite{kucharski2016post}. Fake News refers to articles that meet poor journalistic standards, and contain incorrect or misleading information. It's suggested that these articles, and their tendency to be shared on social media had discernible effect on the events of the USA election, and Brexit \cite{allcott2017social}. \\


Determining whether or not a news article is fake is difficult.  A Stanford study shows students from middle school through college have difficulty distinguishing real news articles from advertisements \cite{wineburg2016evaluating}. As a a result, attempts have been made to automate the detection of fake or misleading news articles \cite{conroy2015automatic}\\

The purpose of this research is to apply natural language processing and machine learning techniques to analyzing the validity of news articles. In particular, we will begin by following the outline presented by Fake News Challenge \cite{fakenewschallenge}. \\

The \emph{stance} of a text is the attitude it expresses towards a particular target \cite{augenstein2016stance}. The first step of the Fake News challenge is to categorize the stance of the body against the stance of the heading of the article. The Fake News Challenge organization provides an implementation, which we will use as our baseline. 


\section{Previous Work}

\subsection{Data Requirements}
Rubin et. al. showed data used to investigate rumors and deception need to have the following characteristics. There must be both truthful and deceptive news within the data set, the format must be accessible, the data must be verifiable, and there must exist data points of comparable lengths and writing styles\cite{Rubin}. \\

\subsection{Stance Detection} 

In “Emergent: a Novel Data Set for Stance Classification” \cite{ferreira2016emergent}, stance detection was used to classify claims in relation to news articles in the Emergent data set. Emergent is a data-set derived from a digital journalism project for rumour debunking. Consisting of 300 claims and 2,595 associated news articles, the Emergent project contains labelled data that can be used in a variety of NLP tasks. \cite{ferreira2016emergent}. Headlines could be classified as either for, against or observing a claim, where observing a claim merely mentions the claim without giving a stance. \\

A headline of a news article and an associated claim were considered. Certain features were extracted, considering first the headline alone and then the headline and claim together. Headline features were extracted using the bag-of-words representation, as well as whether the headline ended in a question mark. The idea of the bag-of-words representation is to quantize each extracted key point into one of visual words, and then “represent each image by a histogram of the visual words. For this purpose, a clustering algorithm (e.g., K-means), is generally used for generating the visual words /cite{zhang2010understanding}”. Features for the distance from the root word to any refuting words (e.g deny) and any reporting words (e.g claim, presumably) were also added. \\

For considering the headline and the claim together, their approach involved constructing a graph, such that each word in the headline and the claim was vertex.  For every word pairing between the claim and the headline an edge was created and assigned a score. If the stems of the words are identical, it is given the max score. If the words are paraphrases, which is determined using the Paraphrase Database (PPDB) \cite{ferreira2016emergent}, they are given the maximum paraphrase score. If neither they are given the minimum score. The Kuhn-Munkres algorithm was run on the graph, which found the maximum scoring word alignment \cite{ferreira2016emergent}. Features were added for negating words and subject-to-verb objects. Vectors were used for comparing the claims to headlines, looking at the cosine similarity of the subject-to-verb objects. \\

Using the headline and headline-claim methods, two overlap thresholds were defined, minimum for and maximum against. If the overlap is higher than the minimum for threshold it is labelled for, if it is less than the maximum against it is labelled against. If it hits neither threshold it is labelled observing. An accuracy of 73\% was achieved on the Emergent test data set using this method. This method was challenged though in detecting observing stances, due to the similarities between the headlines and the claims when a headline is observing. This lead to a mislabelling of the observing claims as for claims. \\

Other work done on stance detection includes “Stance Detection with Bidirectional Conditional Encoding” \cite{augenstein2016stance}. This paper looked at the stances of tweets, given sparse training data or where the target is not explicitly mentioned in the text. Two baselines were used, in a manner of treating stance detection as sentence level sentiment analysis. One was implemented using a Support Vector Machine Classifier and the other with long-short term memory networks (LSTM). LSTM networks were first proposed by Hochreiter and Schmidhuber and it is a gradient based method of learning to store information over extended time intervals \cite{hochreiter1997long}. Their paper found LSTM networks to work best and were used for most of the encodings. \\

Initially, the text and targets were independently encoded as a k-dimensional dense vector space, using two different LSTM networks. The model learned target-independent representation for the tweets, with the initial training encoding the tweets independant of any target. It relied on the nonlinear projection layer to incorporate the target in the stance prediction \cite{augenstein2016stance}. \\

The paper also tested a conditional encoding method. First the target was encoded as a fixed length vector using one LSTM network. The tweet was then encoded using another LSTM network with its initial state using a representation of the target. This encoding was adapted to use bidirectional conditional encoding. One encoding was achieved by reading the target and the tweet from left-to-right, and then another by reading them from right-to-left. This allowed for the context on either side to be considered, in target dependant encoding method. \\

To deal with the small amount of training data, unsupervised pretraining was used, by initialized word embeddings used in the LSTM with a trained word vector model. These embeddings were only used for initialization and were optimized with further training. The paper found that conditional encoding was well suited for learning how to fit a targets with generalized encodings and that bidirectional encoding performed best overall, especially where the target was not explicitly mentioned in the tweet. \\
\section{Deception Detection} 

Conroy et. al. discusses several approaches for automatic fake news detection using natural language processing. This is described as categorizing news on a spectrum based on their level of certainty as well as their veracity (the intention to mislead). The automatic detection of fake news is centered around predicting the chances that any news item is intentionally misleading based on the content of the news item. According to the research, the two main approaches currently being used are linguistic methods and network methods. Both of these methods make use of machine learning on their training data set \cite{conroy2015automatic}. \\

\subsection{Linguistic methods}
These methods utilize knowledge of speech patterns that are able to identify truthfulness and deception more accurately than most humans. Under this approach, a basic way that text is analyzed is considering all words in a block of text as equally significant units. Using natural language processing, this technique would be implemented using \textit{n-grams} to analyze word frequencies and find indicators of deception. This method might also involve tagging the lexical cues of words (also called shallow syntax) or frequencies of words which can uncover linguistic patterns of deception. The techniques under this approach rely heavily on the analysis of the usage of language. They also work very well when combined with other approaches \cite{conroy2015automatic}. 

\subsection{Network methods}
These methods make use of a network of associated information (like metadata) to predict the level of veracity of the content. It is also pointed out that the use of networks of data can provide a means to check the validity of a news item due to the presence of findable truths in the network. This involves making queries on existing knowledge to measure the truthfulness of new news items \cite{conroy2015automatic}. \\

The conclusion drawn was that both methods are very accurate in classifying news items. This gives rise to the use of a hybrid methods that takes into account both approaches to automating fake news detection. Such hybrid methods would have a linguistics-based analysis process that takes into account lexical analysis. It would also be able to perform efficiently in place of a strictly linguistic or network based approach. These techniques should be created with the intent of complementing the processes performed by a researcher in detecting fake news, as opposed to replacing them \cite{conroy2015automatic}. \\


\section{Proposed Approach}

\subsection{Data Available}

\subsection{Baseline Implementation}

\subsection{Potential Improvements} 







%\bibliographystyle{acl}
%\bibliography{acl2017}
\bibliography{proposal}
\bibliographystyle{acl_natbib}

\end{document}
